# ğŸš€ Proyecto Final: Sistema de Procesamiento de Datos Concurrente

## ğŸ“‹ DescripciÃ³n del Proyecto

Crea un **sistema de procesamiento de datos** que implemente mÃºltiples patrones de concurrencia para procesar un gran volumen de datos de manera eficiente.

---

## ğŸ¯ Objetivos

1. **Aplicar todos los patrones aprendidos** en un proyecto real
2. **Manejar un pipeline complejo** de transformaciÃ³n de datos
3. **Implementar monitoring y mÃ©tricas**
4. **Gestionar errores y recuperaciÃ³n**
5. **Optimizar rendimiento** con diferentes estrategias

---

## ğŸ—ï¸ Arquitectura del Sistema

```
Input Data â†’ Validation â†’ Processing â†’ Aggregation â†’ Output
     â†“           â†“           â†“           â†“          â†“
  Worker Pool â†’ Pipeline â†’ Fan-Out/In â†’ Throttling â†’ Storage
```

### Componentes:

1. **Data Ingestion** (Worker Pool)
2. **Validation Pipeline** (Pipeline Pattern)
3. **Parallel Processing** (Fan-Out/Fan-In)
4. **Rate-Limited Storage** (Throttling)
5. **Graceful Shutdown** (Context-based)

---

## ğŸ“ Especificaciones TÃ©cnicas

### Entrada de Datos
```go
type DataRecord struct {
    ID        int       `json:"id"`
    Timestamp time.Time `json:"timestamp"`
    UserID    string    `json:"user_id"`
    Event     string    `json:"event"`
    Value     float64   `json:"value"`
    Metadata  map[string]interface{} `json:"metadata"`
}
```

### Procesamiento Requerido
1. **ValidaciÃ³n**: Verificar campos obligatorios
2. **TransformaciÃ³n**: Normalizar y enriquecer datos
3. **AgregaciÃ³n**: Calcular mÃ©tricas por usuario/evento
4. **Persistencia**: Guardar en "base de datos" (simulada)

### Requisitos de Rendimiento
- Procesar **1000+ records/segundo**
- MÃ¡ximo **10 workers concurrentes** para validaciÃ³n
- MÃ¡ximo **5 conexiones concurrentes** a storage
- **Graceful shutdown** en menos de 5 segundos

---

## ğŸ› ï¸ ImplementaciÃ³n Sugerida

### 1. Estructura del Proyecto
```
proyecto/
â”œâ”€â”€ main.go
â”œâ”€â”€ models/
â”‚   â””â”€â”€ data.go
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ validator.go
â”‚   â”œâ”€â”€ transformer.go
â”‚   â””â”€â”€ aggregator.go
â”œâ”€â”€ storage/
â”‚   â””â”€â”€ mock_db.go
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ monitor.go
â””â”€â”€ README.md
```

### 2. Patrones a Implementar

#### Worker Pool (Ingestion)
```go
func (s *System) ProcessBatch(records []DataRecord) error {
    // Implementar worker pool para procesar lotes
}
```

#### Pipeline (Validation â†’ Transform â†’ Aggregate)
```go
func (s *System) CreatePipeline() (<-chan ProcessedData, error) {
    // Conectar etapas del pipeline
}
```

#### Fan-Out/Fan-In (Parallel Processing)
```go
func (s *System) ParallelProcess(data <-chan DataRecord) <-chan ProcessedData {
    // Distribuir procesamiento entre workers
}
```

#### Throttling (Storage)
```go
func (s *System) ThrottledStore(data <-chan ProcessedData) error {
    // Limitar escrituras concurrentes
}
```

#### Graceful Shutdown
```go
func (s *System) Shutdown(ctx context.Context) error {
    // Parar el sistema elegantemente
}
```

---

## ğŸ“Š MÃ©tricas y Monitoring

### MÃ©tricas a Tracking
- **Throughput**: Records procesados por segundo
- **Latency**: Tiempo promedio de procesamiento
- **Error Rate**: Porcentaje de registros fallidos
- **Goroutines**: NÃºmero activo de goroutines
- **Memory**: Uso de memoria del sistema

### Dashboard Simulado
```go
type Metrics struct {
    ProcessedCount   int64
    ErrorCount      int64
    AverageLatency  time.Duration
    ActiveGoroutines int
}

func (m *Metrics) PrintStatus() {
    // Imprimir mÃ©tricas cada segundo
}
```

---

## ğŸ§ª Testing Strategy

### 1. Unit Tests
- Tests para cada patrÃ³n individualmente
- Mocks para dependencias externas

### 2. Integration Tests
- Test del pipeline completo
- VerificaciÃ³n de throughput

### 3. Load Tests
- Procesar 10,000+ registros
- Medir bajo diferentes cargas

### 4. Benchmarks
- Comparar diferentes configuraciones
- Optimizar nÃºmero de workers

---

## ğŸ¯ Casos de Prueba

### Datos de Entrada
```json
[
  {
    "id": 1,
    "timestamp": "2025-01-15T10:00:00Z",
    "user_id": "user_001",
    "event": "login",
    "value": 1.0,
    "metadata": {"ip": "192.168.1.1"}
  },
  {
    "id": 2,
    "timestamp": "2025-01-15T10:00:05Z",
    "user_id": "user_001",
    "event": "page_view",
    "value": 0.5,
    "metadata": {"page": "/home"}
  }
]
```

### Resultados Esperados
```json
{
  "user_001": {
    "total_events": 2,
    "total_value": 1.5,
    "events": ["login", "page_view"],
    "last_activity": "2025-01-15T10:00:05Z"
  }
}
```

---

## ğŸš€ Extensiones Opcionales

### Nivel Intermedio
1. **Circuit Breaker**: Para servicios externos
2. **Retry Logic**: Con backoff exponencial
3. **Batching**: Agrupar escrituras para eficiencia

### Nivel Avanzado
1. **Dynamic Scaling**: Ajustar workers segÃºn carga
2. **Partitioning**: Distribuir por hash de user_id
3. **Persistence**: Usar base de datos real (PostgreSQL)
4. **Observability**: Integrar con Prometheus/Grafana

---

## ğŸ–ï¸ Criterios de EvaluaciÃ³n

### Funcionalidad (40%)
- âœ… Todos los patrones implementados correctamente
- âœ… Procesa datos sin pÃ©rdida
- âœ… Manejo adecuado de errores

### Performance (30%)
- âœ… Alcanza throughput objetivo
- âœ… Uso eficiente de recursos
- âœ… Graceful shutdown rÃ¡pido

### CÃ³digo (20%)
- âœ… CÃ³digo limpio y documentado
- âœ… Tests comprehensivos
- âœ… Manejo de goroutine leaks

### InnovaciÃ³n (10%)
- âœ… Extensiones creativas
- âœ… Optimizaciones Ãºnicas
- âœ… Monitoring avanzado

---

## ğŸ“š Recursos de Apoyo

- [Effective Go - Concurrency](https://golang.org/doc/effective_go.html#concurrency)
- [Go Blog - Pipelines and Cancellation](https://go.dev/blog/pipelines)
- [Go Concurrency Patterns - Rob Pike](https://www.youtube.com/watch?v=f6kdp27TYZs)

---

Â¡Buena suerte con tu proyecto! ğŸš€ Â¡Muestra el poder de la concurrencia en Go!
